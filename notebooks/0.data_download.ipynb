{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import pandas as pd\n",
    "import requests\n",
    "import zipfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_relative_dir = '../data/'\n",
    "# Ensure the base directory exists\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "\n",
    "# List of folder types and corresponding subfolders\n",
    "folder_structure = {\n",
    "    'landing': ['criminal_incidents', 'property_data'],\n",
    "    'raw': ['criminal_incidents', 'property_data'],\n",
    "    'processed': ['criminal_incidents', 'property_data']\n",
    "}\n",
    "\n",
    "# Create folders based on the structure\n",
    "for folder_type, subfolders in folder_structure.items():\n",
    "    base_path = os.path.join(output_relative_dir, folder_type)\n",
    "    if not os.path.exists(base_path):\n",
    "        os.makedirs(base_path)\n",
    "    \n",
    "    for subfolder in subfolders:\n",
    "        subfolder_path = os.path.join(base_path, subfolder)\n",
    "        if not os.path.exists(subfolder_path):\n",
    "            os.makedirs(subfolder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32262/485473152.py:15: FutureWarning: Passing bytes to 'read_excel' is deprecated and will be removed in a future version. To read from a byte string, wrap it in a `BytesIO` object.\n",
      "  xls = pd.ExcelFile(response.content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names (tables and other data): ['Contents', 'Footnotes', 'Table 01', 'Table 02', 'Table 03', 'Table 04', 'Table 05']\n",
      "Table 'Table 01' saved successfully as ../data/landing/criminal_incidents/criminal_table_01.parquet\n",
      "Table 'Table 02' saved successfully as ../data/landing/criminal_incidents/criminal_table_02.parquet\n",
      "Table 'Table 03' saved successfully as ../data/landing/criminal_incidents/criminal_table_03.parquet\n",
      "Table 'Table 04' saved successfully as ../data/landing/criminal_incidents/criminal_table_04.parquet\n",
      "Table 'Table 05' saved successfully as ../data/landing/criminal_incidents/criminal_table_05.parquet\n"
     ]
    }
   ],
   "source": [
    "# Define the base directory for storing the Parquet files\n",
    "base_dir = '../data/landing/criminal_incidents/'\n",
    "\n",
    "# Ensure the base directory exists\n",
    "if not os.path.exists(base_dir):\n",
    "    os.makedirs(base_dir)\n",
    "\n",
    "# File URL for downloading the Excel file\n",
    "url = 'https://files.crimestatistics.vic.gov.au/2024-06/Data_Tables_LGA_Criminal_Incidents_Year_Ending_March_2024.xlsx'\n",
    "\n",
    "# Download the Excel file content directly into memory\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Load the Excel content into a pandas ExcelFile object directly from memory\n",
    "    xls = pd.ExcelFile(response.content)\n",
    "\n",
    "    # Get all sheet names (table names)\n",
    "    table_names = xls.sheet_names\n",
    "    print(\"Sheet names (tables and other data):\", table_names)\n",
    "\n",
    "    # Initialize a counter for table naming\n",
    "    table_counter = 1\n",
    "\n",
    "    # Iterate over each sheet and save only tables as Parquet files\n",
    "    for sheet in table_names:\n",
    "        # Assuming table sheets contain the word 'Table'\n",
    "        if 'Table' in sheet or sheet.lower().startswith('table'):\n",
    "            # Read the sheet into a DataFrame\n",
    "            df = pd.read_excel(xls, sheet_name=sheet)\n",
    "\n",
    "            # Save the table as a Parquet file with the naming convention 'criminal_table_X.parquet'\n",
    "            parquet_file_name = f'criminal_table_{table_counter:02}.parquet'\n",
    "            parquet_output_path = os.path.join(base_dir, parquet_file_name)\n",
    "            df.to_parquet(parquet_output_path, index=False)\n",
    "            print(f\"Table '{sheet}' saved successfully as {parquet_output_path}\")\n",
    "\n",
    "            # Increment table counter for each saved table\n",
    "            table_counter += 1\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_32262/1482215580.py:15: FutureWarning: Passing bytes to 'read_excel' is deprecated and will be removed in a future version. To read from a byte string, wrap it in a `BytesIO` object.\n",
      "  xls = pd.ExcelFile(response.content)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sheet names (tables and other data): ['Contents', 'Footnotes', 'Table 01', 'Table 02', 'Table 03', 'Table 04', 'Table 05', 'Table 06']\n",
      "Table 'Table 01' saved successfully as ../data/landing/property_data/property_table_01.parquet\n",
      "Table 'Table 02' saved successfully as ../data/landing/property_data/property_table_02.parquet\n",
      "Table 'Table 03' saved successfully as ../data/landing/property_data/property_table_03.parquet\n",
      "Table 'Table 04' saved successfully as ../data/landing/property_data/property_table_04.parquet\n",
      "Table 'Table 05' saved successfully as ../data/landing/property_data/property_table_05.parquet\n",
      "Table 'Table 06' saved successfully as ../data/landing/property_data/property_table_06.parquet\n"
     ]
    }
   ],
   "source": [
    "# Define the output directory inside WSL\n",
    "output_relative_dir = '../data/landing/property_data/'\n",
    "\n",
    "# Ensure the directory exists\n",
    "if not os.path.exists(output_relative_dir):\n",
    "    os.makedirs(output_relative_dir)\n",
    "\n",
    "# File URL for downloading the Excel file\n",
    "url = 'https://files.crimestatistics.vic.gov.au/2024-06/Data_Tables_Property_Items_Visualisation_Year_Ending_March_2024.xlsx'\n",
    "\n",
    "# Download the Excel file content directly into memory\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    # Load the Excel content into a pandas ExcelFile object directly from memory\n",
    "    xls = pd.ExcelFile(response.content)\n",
    "\n",
    "    # Get all sheet names (table names)\n",
    "    sheet_names = xls.sheet_names\n",
    "    print(\"Sheet names (tables and other data):\", sheet_names)\n",
    "\n",
    "    # Initialize a counter for table naming\n",
    "    table_counter = 1\n",
    "\n",
    "    # Iterate over each sheet and save them accordingly\n",
    "    for sheet in sheet_names:\n",
    "        # Read the sheet into a DataFrame\n",
    "        df = pd.read_excel(xls, sheet_name=sheet)\n",
    "\n",
    "        # Only process and save sheets that are tables (skip \"Contents\" and \"Footnotes\")\n",
    "        if 'Table' in sheet or sheet.lower().startswith('table'):\n",
    "            # Handle inconsistent data types by converting all columns to strings\n",
    "            df = df.astype(str)\n",
    "\n",
    "            # Save the table as a Parquet file with the naming convention 'property_table_X.parquet'\n",
    "            parquet_file_name = f'property_table_{table_counter:02}.parquet'\n",
    "            parquet_output_path = os.path.join(output_relative_dir, parquet_file_name)\n",
    "            df.to_parquet(parquet_output_path, index=False)\n",
    "            print(f\"Table '{sheet}' saved successfully as {parquet_output_path}\")\n",
    "\n",
    "            # Increment table counter for each saved table\n",
    "            table_counter += 1\n",
    "\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SA2_district_boundaries.dbf',\n",
       " 'SA2_district_boundaries.shx',\n",
       " 'SA2_2021_AUST_SHP_GDA2020.zip',\n",
       " 'SA2_district_boundaries.shp',\n",
       " 'SA2_district_boundaries.prj',\n",
       " 'SA2_district_boundaries.xml']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL for the ZIP file\n",
    "url = 'https://www.abs.gov.au/statistics/standards/australian-statistical-geography-standard-asgs-edition-3/jul2021-jun2026/access-and-downloads/digital-boundary-files/SA2_2021_AUST_SHP_GDA94.zip'\n",
    "\n",
    "# Define the output directory and file name\n",
    "output_dir = '../data/landing/boundaries/'\n",
    "zip_file_path = os.path.join(output_dir, 'SA2_2021_AUST_SHP_GDA2020.zip')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Download the ZIP file and save it locally\n",
    "response = requests.get(url)\n",
    "with open(zip_file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Extract and rename all files in the ZIP archive\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all files to the output directory\n",
    "    zip_ref.extractall(output_dir)\n",
    "    # List all files in the ZIP archive\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "    # Rename each file in the output directory to start with 'SA2_district_boundaries'\n",
    "    for original_file in file_list:\n",
    "        original_path = os.path.join(output_dir, original_file)\n",
    "        # Get the file extension\n",
    "        file_extension = os.path.splitext(original_file)[1]\n",
    "        # Define the new file name\n",
    "        new_file_name = f\"SA2_district_boundaries{file_extension}\"\n",
    "        new_file_path = os.path.join(output_dir, new_file_name)\n",
    "        # Rename the file if it exists\n",
    "        if os.path.exists(original_path):\n",
    "            os.rename(original_path, new_file_path)\n",
    "\n",
    "# Return the list of renamed files\n",
    "renamed_files = os.listdir(output_dir)\n",
    "renamed_files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved as Parquet at: ../data/landing/suburb_match/suburb_match.parquet\n",
      "['suburb_match.csv', 'suburb_match.parquet']\n"
     ]
    }
   ],
   "source": [
    "# Define the URL for the CSV file\n",
    "url = 'https://www.matthewproctor.com/Content/postcodes/australian_postcodes.csv'\n",
    "\n",
    "# Define the output directory and file name (using current directory)\n",
    "output_dir = '../data/landing/suburb_match/'\n",
    "csv_file_path = os.path.join(output_dir, 'suburb_match.csv')\n",
    "parquet_file_path = os.path.join(output_dir, 'suburb_match.parquet')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Download the CSV file and save it locally\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200:\n",
    "    with open(csv_file_path, 'wb') as file:\n",
    "        file.write(response.content)\n",
    "\n",
    "    # Load the CSV file into a pandas DataFrame\n",
    "    df = pd.read_csv(csv_file_path)\n",
    "\n",
    "    # Save the DataFrame as a Parquet file\n",
    "    df.to_parquet(parquet_file_path, index=False)\n",
    "\n",
    "    # Return the path of the saved Parquet file\n",
    "    print(f\"File saved as Parquet at: {parquet_file_path}\")\n",
    "else:\n",
    "    print(\"Failed to download the file. Status code:\", response.status_code)\n",
    "\n",
    "# Return the list of files in the output directory\n",
    "downloaded_files = os.listdir(output_dir)\n",
    "print(downloaded_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['parkres.zip',\n",
       " 'parkres.prj',\n",
       " 'parkres.cpg',\n",
       " 'parkres.dbf',\n",
       " 'parkres.txt',\n",
       " 'll_gda94',\n",
       " 'parkres.shx',\n",
       " 'parkres.shp',\n",
       " 'parkres.html']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the URL for the ZIP file\n",
    "url = 'https://s3.ap-southeast-2.amazonaws.com/cl-isd-prd-datashare-s3-delivery/Order_Y9LSRC.zip'\n",
    "\n",
    "# Define the output directory and file name\n",
    "output_dir = '../data/landing/parkres/'\n",
    "zip_file_path = os.path.join(output_dir, 'parkres.zip')\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Download the ZIP file and save it locally\n",
    "response = requests.get(url)\n",
    "with open(zip_file_path, 'wb') as file:\n",
    "    file.write(response.content)\n",
    "\n",
    "# Extract and rename all files in the ZIP archive\n",
    "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
    "    # Extract all files to the output directory\n",
    "    zip_ref.extractall(output_dir)\n",
    "    # List all files in the ZIP archive\n",
    "    file_list = zip_ref.namelist()\n",
    "\n",
    "    # Rename each file in the output directory to start with 'parkres'\n",
    "    for original_file in file_list:\n",
    "        original_path = os.path.join(output_dir, original_file)\n",
    "        # Get the file extension\n",
    "        file_extension = os.path.splitext(original_file)[1]\n",
    "        # Define the new file name\n",
    "        new_file_name = f\"parkres{file_extension}\"\n",
    "        new_file_path = os.path.join(output_dir, new_file_name)\n",
    "        # Rename the file if it exists\n",
    "        if os.path.exists(original_path):\n",
    "            os.rename(original_path, new_file_path)\n",
    "\n",
    "# Return the list of renamed files\n",
    "renamed_files = os.listdir(output_dir)\n",
    "renamed_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Excel file downloaded and saved at: ../data/landing/postcode/postcode_ref.xls\n",
      "File converted to CSV and saved at: ../data/landing/postcode/postcode_ref.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the URL of the file to download\n",
    "url = \"https://www.health.vic.gov.au/sites/default/files/2024-07/postcode-locality-reference.xls\"\n",
    "\n",
    "# Define the output directory and file name\n",
    "output_dir = '../data/landing/postcode/'  # Change this to your desired directory\n",
    "xls_file_name = 'postcode_ref.xls'\n",
    "csv_file_name = 'postcode_ref.csv'\n",
    "\n",
    "# Ensure the output directory exists\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir)\n",
    "\n",
    "# Full path to save the Excel and CSV files\n",
    "xls_file_path = os.path.join(output_dir, xls_file_name)\n",
    "csv_file_path = os.path.join(output_dir, csv_file_name)\n",
    "\n",
    "# Download the Excel file\n",
    "response = requests.get(url)\n",
    "\n",
    "# Check if the download was successful (HTTP 200 OK)\n",
    "if response.status_code == 200:\n",
    "    # Write the Excel file content to the local system\n",
    "    with open(xls_file_path, 'wb') as f:\n",
    "        f.write(response.content)\n",
    "    print(f\"Excel file downloaded and saved at: {xls_file_path}\")\n",
    "    \n",
    "    # Load the Excel file into a pandas DataFrame\n",
    "    df = pd.read_excel(xls_file_path)\n",
    "\n",
    "    # Save the DataFrame as a CSV file\n",
    "    df.to_csv(csv_file_path, index=False)\n",
    "    print(f\"File converted to CSV and saved at: {csv_file_path}\")\n",
    "else:\n",
    "    print(f\"Failed to download the file. Status code: {response.status_code}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
